#  数理统计

##  最大似然估计，最大后验估计，贝叶斯估计联系与区别

###  概率与统计的区别

概率（probabilty）和统计（statistics）看似两个相近的概念，其实研究的问题刚好相反。

概率研究的问题是，已知一个模型和参数，怎么去预测这个模型产生的结果的特性（例如均值，方差，协方差等等）。 举个例子，我想研究怎么养猪（模型是猪），我选好了想养的品种、喂养方式、猪棚的设计等等（选择参数），我想知道我养出来的猪大概能有多肥，肉质怎么样（预测结果）。

统计研究的问题则相反。统计是，有一堆数据，要利用这堆数据去预测模型和参数。仍以猪为例。现在我买到了一堆肉，通过观察和判断，我确定这是猪肉（这就确定了模型。在实际研究中，也是通过观察数据推测模型是／像高斯分布的、指数分布的、拉普拉斯分布的等等），然后，可以进一步研究，判定这猪的品种、这是圈养猪还是跑山猪还是网易猪，等等（推测模型参数）。

一句话总结：概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。 

### 最大似然估计

前文提到，最大似然估计(maximum likelihood estimates，MLE)是实际中使用非常广泛的一种方法，用我们老师的一句最简单的话来总结最大似然估计，就是“谁大像谁”。 
说到最大似然估计与最大后验估计，最好的例子自然就是抛硬币了。本文也不免俗，同样以抛硬币作为例子。 
于是我们拿这枚硬币抛了10次，得到的数据X是：反正正正正反正正正反。我们想求的正面概率θ是模型参数，而抛硬币模型我们可以假设是二项分布。 
在概率论和统计学中，二项分布（Binomial distribution）是n个独立的是/非试验中成功的次数的离散概率分布，其中每次试验的成功概率为p。这样的单次成功/失败试验又称为伯努利试验。实际上，当n = 1时，二项分布就是伯努利分布。 

伯努利分布（Bernoulli distribution，又名两点分布或者0-1分布，是一个离散型概率分布，为纪念瑞士科学家雅各布·伯努利而命名。)若伯努利试验成功，则伯努利随机变量取值为0。记其成功概率为 p(0≤p≤1)p(0≤p≤1),失败概率为 q=1−pq=1−p。

### 最大后验估计

[链接link](https://blog.csdn.net/bitcarmanlee/article/details/81417151)



