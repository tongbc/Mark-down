##  机器学习比赛
### correlation相关程度，皮尔逊
```python
df.corr()
```
None of the 256 variables have correlation with the target greater than absolute value 0.04. Therefore if you use LR to model target you score a low CV 0.530 because LR treats the variables as independent and doesn't utilize interactions.

### sklean.Linear_model.LogisticRegression

```python
clf = LogisticRegression(solver='liblinear',penalty='l2',C=1.0)
```
Penalty:l1 or l2正则
C 正则化的严重程度，C越小，模型越简单

### sklearn.model_selection.Stratified 
```python
skf = StratifiedKFold(n_splits=5, random_state=42)
for train_index, test_index in skf.split(train.iloc[:,1:-1], train['target']):
```
### plt.hist() 
```python
plt.hist(df["col"].values,bins=200)
```
bins:多少个柱体
### train.describe() 
```python
train.describe()
```
count，mean，std，min等等统计数值
### pd.concat()
```python
 traintest = pd.concat([train,test], axis=0, ignore_index=True).reset_index(drop=True)
   
```
### from sklearn.svm import SVC
```python
clf = SVC(probability=True,kernel='poly',degree=4,gamma='auto')
clf.fit(train3[train_index,:],train2.loc[train_index]['target'])
```
kernel:   
‘linear’:线性核函数  
‘poly’：多项式核函数  
‘rbf’：径像核函数/高斯核  
‘sigmod’:sigmod核函数  
‘precomputed’:核矩阵  
degree:
多项式核函数的阶数

### tqdm
```python
import numpy as np
from tqdm import tqdm_notebook as tqdm
import time
for i in tqdm(range(100)):
    time.sleep(0.01)
```
###  VarianceThreshold

```python
from sklearn.feature_selection import VarianceThreshold

sel = VarianceThreshold(threshold=1.5).fit(train2[cols])
train3 = sel.transform(train2[cols])
test3 = sel.transform(test2[cols])
```
###  均方根对数误差 （root mean squared logarithmic error） RMSLE

```python
def rmsle(y, y_pred):
    assert len(y) == len(y_pred)
    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]
    return (sum(to_sum) * (1.0/len(y))) ** 0.5
```
![gongshi](D://md_images/RMSLE.jpg)
使用RMSLE的好处一：

  假如真实值为1000，若果预测值是600，那么RMSE=400， RMSLE=0.510

  假如真实值为1000，若预测结果为1400， 那么RMSE=400， RMSLE=0.336

  可以看出来在均方根误差相同的情况下，预测值比真实值小这种情况的错误比较大，即对于预测值小这种情况惩罚较大。

使用RMSLE的好处二：

  直观的经验是这样的，当数据当中有少量的值和真实值差值较大的时候，使用log函数能够减少这些值对于整体误差的影响。



### WOE(WEIGHT OF EVIDENCE)

```python
# https://www.listendata.com/2015/03/weight-of-evidence-woe-and-information.html
def woe(X, y):
    tmp = pd.DataFrame()
    tmp["variable"] = X
    tmp["target"] = y
    var_counts = tmp.groupby("variable")["target"].count()
    var_events = tmp.groupby("variable")["target"].sum()
    var_nonevents = var_counts - var_events
    tmp["var_counts"] = tmp.variable.map(var_counts)
    tmp["var_events"] = tmp.variable.map(var_events)
    tmp["var_nonevents"] = tmp.variable.map(var_nonevents)
    events = sum(tmp["target"] == 1)
    nonevents = sum(tmp["target"] == 0)
    tmp["woe"] = np.log(((tmp["var_nonevents"])/nonevents)/((tmp["var_events"])/events))
    tmp["woe"] = tmp["woe"].replace(np.inf, 0).replace(-np.inf, 0)
    tmp["iv"] = (tmp["var_nonevents"]/nonevents - tmp["var_events"]/events) * tmp["woe"]
    iv = tmp.groupby("variable")["iv"].last().sum()
    return tmp["woe"], tmp["iv"], iv
```

### df[features].skew(axis=1)

```python
plt.figure(figsize=(16,6))
plt.title("Distribution of skew per row in the train and test set")
sns.distplot(train_df[features].skew(axis=1),color="red", kde=True,bins=120, label='train')
sns.distplot(test_df[features].skew(axis=1),color="orange", kde=True,bins=120, label='test')
plt.legend()
plt.show()
```

偏度（skewness），是统计数据分布偏斜方向和程度的度量，是统计数据分布非对称程度的数字特征。偏度(Skewness)亦称偏态、偏态系数。 
表征概率分布密度曲线相对于平均值不对称程度的特征数。直观看来就是密度函数曲线尾部的相对长度。 
定义上偏度是样本的三阶标准化矩：skew(X)=E[((X−μ)/σ)^3]

![img](http://images.51cto.com/files/uploadimg/20100408/161111811.jpg)

### df[features].kurtosis(axis=1)

```python
plt.figure(figsize=(16,6))
plt.title("Distribution of kurtosis per row in the train and test set")
sns.distplot(train_df[features].kurtosis(axis=1),color="darkblue", kde=True,bins=120, label='train')
sns.distplot(test_df[features].kurtosis(axis=1),color="yellow", kde=True,bins=120, label='test')
plt.legend()
plt.show()
```

峰度是描述总体中所有取值分布形态陡缓程度的统计量。这个统计量需要与正态分布相比较，峰度为0表示该总体数据分布与正态分布的陡缓程度相同；峰度大于0表示该总体数据分布与正态分布相比较为陡峭，为尖顶峰；峰度小于0表示该总体数据分布与正态分布相比较为平坦，为平顶峰。峰度的绝对值数值越大表示其分布形态的陡缓程度与正态分布的差异程度越大。

![](http://images.51cto.com/files/uploadimg/20100408/161046770.jpg)







### https://www.kaggle.com/tbctheprocess/getting-started-santander-e97fcb/edit

https://www.kaggle.com/gpreda/santander-eda-and-prediction

