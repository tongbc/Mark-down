##  机器学习比赛
### correlation相关程度，皮尔逊
```python
df.corr()
```
None of the 256 variables have correlation with the target greater than absolute value 0.04. Therefore if you use LR to model target you score a low CV 0.530 because LR treats the variables as independent and doesn't utilize interactions.

### sklean.Linear_model.LogisticRegression

```python
clf = LogisticRegression(solver='liblinear',penalty='l2',C=1.0)
```
Penalty:l1 or l2正则
C 正则化的严重程度，C越小，模型越简单

### sklearn.model_selection.Stratified 
```python
skf = StratifiedKFold(n_splits=5, random_state=42)
for train_index, test_index in skf.split(train.iloc[:,1:-1], train['target']):
```
### plt.hist() 
```python
plt.hist(df["col"].values,bins=200)
```
bins:多少个柱体
### train.describe() 
```python
train.describe()
```
count，mean，std，min等等统计数值
### pd.concat()
```python
 traintest = pd.concat([train,test], axis=0, ignore_index=True).reset_index(drop=True)
   
```
### from sklearn.svm import SVC
```python
clf = SVC(probability=True,kernel='poly',degree=4,gamma='auto')
clf.fit(train3[train_index,:],train2.loc[train_index]['target'])
```
kernel:   
‘linear’:线性核函数  
‘poly’：多项式核函数  
‘rbf’：径像核函数/高斯核  
‘sigmod’:sigmod核函数  
‘precomputed’:核矩阵  
degree:
多项式核函数的阶数

### tqdm
```python
import numpy as np
from tqdm import tqdm_notebook as tqdm
import time
for i in tqdm(range(100)):
    time.sleep(0.01)
```
###  VarianceThreshold

```python
from sklearn.feature_selection import VarianceThreshold

sel = VarianceThreshold(threshold=1.5).fit(train2[cols])
train3 = sel.transform(train2[cols])
test3 = sel.transform(test2[cols])
```
###  均方根对数误差 （root mean squared logarithmic error） RMSLE

```python
def rmsle(y, y_pred):
    assert len(y) == len(y_pred)
    to_sum = [(math.log(y_pred[i] + 1) - math.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]
    return (sum(to_sum) * (1.0/len(y))) ** 0.5
```
![gongshi](D://md_images/RMSLE.jpg)
使用RMSLE的好处一：

  假如真实值为1000，若果预测值是600，那么RMSE=400， RMSLE=0.510

  假如真实值为1000，若预测结果为1400， 那么RMSE=400， RMSLE=0.336

  可以看出来在均方根误差相同的情况下，预测值比真实值小这种情况的错误比较大，即对于预测值小这种情况惩罚较大。

使用RMSLE的好处二：

  直观的经验是这样的，当数据当中有少量的值和真实值差值较大的时候，使用log函数能够减少这些值对于整体误差的影响。